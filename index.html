<html>
  <body>
    <div class="container">
      <canvas id="wave"> </canvas>

      <button onclick="startRecording()">Start recording</button>
    </div>
  </body>
</html>
<script>

let points = [];

const samples = 256;
const canvas = document.getElementById('wave');
let ctx = canvas.getContext('2d');

const dpr = window.devicePixelRatio || 1;
const padding = 10;
canvas.width = canvas.offsetWidth * dpr;

canvas.height = (canvas.offsetHeight + padding * 2) * dpr;
//ctx.scale(dpr, dpr);
ctx.translate(0, canvas.offsetHeight / 2 + padding);
const drawWave = _ => {

  const width = canvas.width;
  const height = canvas.height;

  ctx.clearRect(0, -height, width, height * 2);
  ctx.fillStyle = '#FF0000';

  ctx.beginPath();
  ctx.moveTo(0, 0);
  for (let x = 0; x < samples; x++) {
    //    console.log("points", points[x]);
    ctx.lineTo(x * 10, points[x]);
    ctx.stroke()
    //ctx.fillRect(x * 10, 100 + points[x], 5, 5);
    ctx.moveTo(x * 10, points[x]);
  }

}

async function recordMic() {
  let stream = null;

  try {
    stream = await navigator.mediaDevices.getUserMedia({
      audio: true,
    });
  } catch(err) {
    console.log("There was an error", err);
  }

  let options = {
    mimeType: "video/webm; codecs=vp9"
  };
  console.log(options);
  var mediaRecorder = new MediaRecorder(stream, options);

  mediaRecorder.ondataavailable = handleDataAvailable;
  mediaRecorder.start();

  setTimeout(() => {
    console.log("stopping");
    mediaRecorder.stop();
  }, 3000);

  let recordedChunks = [];
  async function handleDataAvailable(event) {
    console.log("data-available");
    if (event.data.size > 0) {
      recordedChunks.push(event.data);
      console.log(recordedChunks);
      await download();
    } else {
      // ...
    }
  }

  async function download() {
    var audio = await (new Blob(recordedChunks, {
      type: "video/webm"
    })).arrayBuffer();
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    audioCtx.decodeAudioData(audio)
  }


  var audioCtx = new (window.AudioContext || window.webkitAudioContext)();
  var source = audioCtx.createMediaStreamSource(stream);

  try {
    await audioCtx.audioWorklet.addModule('http://localhost:8000/pcm-processor.js');
  } catch(e) {
    console.error("Doh", e);
  }

  const pcmProcessor = new AudioWorkletNode(audioCtx, 'pcm-processor')

  source.connect(pcmProcessor);

  drawWave();
  setInterval(_ => {
    drawWave();
  }, 20);
  pcmProcessor.port.onmessage = (e) => {
    if (e.data.eventType === 'data') {
      const audioData = e.data.audioBuffer;
      if (points.length === samples) {
        points.shift();
      }

      points.push(audioData * 100);
    }

    if (e.data.eventType === 'stop') {
      // recording has stopped
    }
  };

  pcmProcessor.connect(audioCtx.destination);

  return pcmProcessor;

}

async function startRecording(e) {
  console.log("Starting to record");

  const pcmProcessor = await recordMic()
  pcmProcessor.parameters.get('isRecording').setValueAtTime(1, 0);

}

window.addEventListener('DOMContentLoaded', async e => {
});

</script>
